{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "TEST_DATA_PATH = \"./data/\"\n",
    "MODEL_PATH = \"./experiments/models/crn-model-512-50-b16.pt\"\n",
    "\n",
    "N_FFT = 512\n",
    "RESAMPLE_SAMPLERATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set\n",
    "test_dataset = data.TestNoisySpeech(TEST_DATA_PATH)\n",
    "_, _, input_samplerate = test_dataset.__getitem__(0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, collate_fn=data.collate_fn)\n",
    "\n",
    "print(f\"Dataset length: {len(test_dataset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model here\n",
    "class YourModel:\n",
    "    pass\n",
    "\n",
    "model = YourModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from state_dict\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre- and post-processors\n",
    "class PreProcessor(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_samplerate=16000,\n",
    "        resample_samplerate=16000,\n",
    "        n_fft=480,\n",
    "        power=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_size = n_fft // 2 + 1\n",
    "        self.resample = transforms.Resample(input_samplerate, resample_samplerate)\n",
    "        self.transform = transforms.Spectrogram(n_fft=n_fft, power=power, normalized=True, window_fn=torch.hann_window)\n",
    "        \n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        resampled = self.resample(waveform)\n",
    "        spec = self.transform(resampled)\n",
    "        spec = spec.permute(0, 2, 1)\n",
    "        return spec\n",
    "\n",
    "\n",
    "class PostProcessor(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_samplerate = 16000,\n",
    "        resample_samplerate = 16000,\n",
    "        n_fft = 480\n",
    "    ):\n",
    "        super().__init__()\n",
    "        n_fft = n_fft\n",
    "        self.resample = transforms.Resample(resample_samplerate, output_samplerate)\n",
    "        self.transform = transforms.InverseSpectrogram(n_fft=n_fft, normalized=True, window_fn=torch.hann_window)\n",
    "\n",
    "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
    "        spec = spec.permute(0, 2, 1)\n",
    "        waveform = self.transform(spec)\n",
    "        resampled = self.resample(waveform)\n",
    "        return resampled\n",
    "    \n",
    "    \n",
    "preprocessor = PreProcessor(\n",
    "    input_samplerate=input_samplerate, \n",
    "    resample_samplerate=RESAMPLE_SAMPLERATE,\n",
    "    n_fft=N_FFT,\n",
    "    power=None,\n",
    ")\n",
    "\n",
    "postprocessor = PostProcessor(\n",
    "    output_samplerate=input_samplerate, \n",
    "    resample_samplerate=RESAMPLE_SAMPLERATE,\n",
    "    n_fft=N_FFT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE loss function\n",
    "def calculate_mae(\n",
    "    dataloader, \n",
    "    model, \n",
    "    preprocessor,\n",
    "):\n",
    "    mae_losses = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "        for noisy_batch, clean_batch, _ in dataloader:\n",
    "            noisy_spec = preprocessor(noisy_batch)\n",
    "            clean_spec = preprocessor(clean_batch)\n",
    "\n",
    "            est_spec, _ = model(noisy_spec)\n",
    "\n",
    "            mae_loss = F.l1_loss(est_spec.abs(), clean_spec.abs())\n",
    "            mae_losses.append(mae_loss)\n",
    "\n",
    "    average_score = sum(mae_losses) / len(mae_losses)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute score\n",
    "score = calculate_mae(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "\n",
    "score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listening Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IDs of examples to investigate\n",
    "idx_list = [0, 100, 200]\n",
    "\n",
    "single_example_set = Subset(test_dataset, idx_list)\n",
    "single_example_loader = torch.utils.data.DataLoader(single_example_set, batch_size=1, collate_fn=data.collate_fn)\n",
    "iterable_loader = iter(single_example_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference + plot spectrogram + display audio\n",
    "noisy_batch, clean_batch, sr = next(iterable_loader)\n",
    "noisy_spec = preprocessor(noisy_batch).to(DEVICE)\n",
    "clean_spec = preprocessor(clean_batch).to(DEVICE)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    enhanced_spec, _ = model(noisy_spec)\n",
    "\n",
    "enhanced_batch = postprocessor(enhanced_spec.to('cpu'))\n",
    "clean_audio = postprocessor(clean_spec.to('cpu'))\n",
    "noisy_audio = postprocessor(noisy_spec.to('cpu'))\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(noisy_spec[0,:,:].to('cpu').abs().log().mT.numpy(),origin='lower', aspect=\"auto\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(enhanced_spec[0,:,:].to('cpu').abs().log().mT.detach().numpy(),origin='lower', aspect=\"auto\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(clean_spec[0,:,:].to('cpu').abs().log().mT.numpy(),origin='lower', aspect=\"auto\")\n",
    "plt.show()\n",
    "\n",
    "import IPython\n",
    "IPython.display.display(IPython.display.Audio(noisy_batch[0,:].detach().numpy(),rate=int(sr)))\n",
    "IPython.display.display(IPython.display.Audio(enhanced_batch[0,:].detach().numpy(),rate=int(sr)))\n",
    "IPython.display.display(IPython.display.Audio(clean_batch[0,:],rate=int(sr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PESQ Score (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.audio.pesq import perceptual_evaluation_speech_quality\n",
    "\n",
    "# PESQ eval function\n",
    "def calculate_pesq(\n",
    "    dataloader, \n",
    "    model, \n",
    "    preprocessor,\n",
    "    postprocessor, \n",
    "):\n",
    "    pesq_scores = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "        for noisy_batch, clean_batch, _ in dataloader:\n",
    "            noisy_spec = preprocessor(noisy_batch)\n",
    "            est_spec, _ = model(noisy_spec)\n",
    "            est_batch = postprocessor(est_spec)\n",
    "\n",
    "            pesq_score = perceptual_evaluation_speech_quality(est_batch, clean_batch, fs=16000, mode=\"wb\")\n",
    "            pesq_scores.append(pesq_score)\n",
    "\n",
    "    average_score = sum(pesq_scores) / len(pesq_scores)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute score\n",
    "score = calculate_pesq(\n",
    "    dataloader=test_loader,\n",
    "    model=model,\n",
    "    preprocessor=preprocessor,\n",
    "    postprocessor=postprocessor,\n",
    ")\n",
    "\n",
    "score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
