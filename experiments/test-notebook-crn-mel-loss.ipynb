{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734704a-a637-43d8-b57a-c53a7dc330ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "SAVE_PATH = \"./experiments/models/\"\n",
    "\n",
    "N_FFT = 512\n",
    "N_MELS = 50\n",
    "GRU_LAYERS = 2\n",
    "RESAMPLE_SAMPLERATE = 16000\n",
    "ALPHA = 0.4\n",
    "\n",
    "LR = 1e-3\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42417ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_samplerate=16000,\n",
    "        resample_samplerate=16000,\n",
    "        n_fft=480,\n",
    "        power=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_size = n_fft // 2 + 1\n",
    "        self.resample = transforms.Resample(input_samplerate, resample_samplerate)\n",
    "        self.transform = transforms.Spectrogram(n_fft=n_fft, power=power, normalized=True, window_fn=torch.hann_window)\n",
    "        \n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        resampled = self.resample(waveform)\n",
    "        spec = self.transform(resampled)\n",
    "        spec = spec.permute(0, 2, 1)\n",
    "        return spec\n",
    "\n",
    "\n",
    "class PostProcessor(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_samplerate = 16000,\n",
    "        resample_samplerate = 16000,\n",
    "        n_fft = 480\n",
    "    ):\n",
    "        super().__init__()\n",
    "        n_fft = n_fft\n",
    "        self.resample = transforms.Resample(resample_samplerate, output_samplerate)\n",
    "        self.transform = transforms.InverseSpectrogram(n_fft=n_fft, normalized=True, window_fn=torch.hann_window)\n",
    "\n",
    "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
    "        spec = spec.permute(0, 2, 1)\n",
    "        waveform = self.transform(spec)\n",
    "        resampled = self.resample(waveform)\n",
    "        return resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75e70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelLoss(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate,\n",
    "        n_stft=101,\n",
    "        n_mels=10,\n",
    "        device='cpu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.melscale_transform = torchaudio.functional.melscale_fbanks(\n",
    "            n_stft,\n",
    "            f_min = 0,\n",
    "            f_max = sample_rate / 2.0,\n",
    "            n_mels = n_mels,\n",
    "            sample_rate = sample_rate,\n",
    "            norm = 'slaney',\n",
    "        ).to(device)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"MelLoss\"\n",
    "        \n",
    "    def forward(self, estimated_spec, reference_spec):        \n",
    "        mel_error_spec = torch.matmul(            \n",
    "            (estimated_spec - reference_spec).abs()**2,\n",
    "            self.melscale_transform\n",
    "        )\n",
    "        return mel_error_spec.clamp(min=1e-6).log().mean(dim=-2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd49834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader, \n",
    "    dataset, \n",
    "    model, \n",
    "    preprocessor, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    scheduler=None, \n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "):\n",
    "    size = len(dataset)\n",
    "    model.train()\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (noisy_batch, clean_batch, _) in enumerate(dataloader):\n",
    "            noisy_spec = preprocessor(noisy_batch).to(device)\n",
    "            clean_spec = preprocessor(clean_batch).to(device)\n",
    "\n",
    "            batch_size = noisy_batch.shape[0]\n",
    "\n",
    "            est_clean_spec, _ = model(noisy_spec)\n",
    "            loss = loss_fn(est_clean_spec, clean_spec)\n",
    "            \n",
    "            if scheduler:\n",
    "                scheduler.step(loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch + 1) % 10 == 0:\n",
    "                torch.save(model, SAVE_PATH + f\"crn-model-checkpoint.pt\")\n",
    "\n",
    "            if (batch + 1) % 10 == 0:\n",
    "                curr_time = time.perf_counter()\n",
    "                loss, current = loss.item(), 1 + (batch) * batch_size + epoch * size\n",
    "                print(f\"loss: {loss:>7f} [{current:>5d}/{size*epochs:>5d}] at {curr_time-start_time:>5f} sec\")\n",
    "                start_time = curr_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6cfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels,\n",
    "        out_channels, \n",
    "        kernel_size=(2, 5), \n",
    "        stride=(1, 2), \n",
    "        padding=(0, 2), \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        return conv_out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels,\n",
    "        out_channels, \n",
    "        kernel_size=(2, 5), \n",
    "        stride=(1, 2), \n",
    "        padding=(0, 2), \n",
    "        is_last=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.LeakyReLU() if not is_last else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        return conv_out\n",
    "\n",
    "\n",
    "class CRN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft=512,\n",
    "        gru_layers=3,\n",
    "        device='cpu',\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-9\n",
    "        self.device = device\n",
    "        self.spec_size = n_fft // 2 + 1\n",
    "\n",
    "        self.en_conv1 = EncoderBlock(in_channels=1, out_channels=16)\n",
    "        self.en_conv2 = EncoderBlock(in_channels=16, out_channels=32)\n",
    "        self.en_conv3 = EncoderBlock(in_channels=32, out_channels=64)\n",
    "        self.en_conv4 = EncoderBlock(in_channels=64, out_channels=128)\n",
    "        self.en_conv5 = EncoderBlock(in_channels=128, out_channels=256)\n",
    "\n",
    "        self.gru = nn.GRU(input_size=256 * 17, hidden_size=256 * 17, num_layers=gru_layers, bidirectional=False, batch_first=True)\n",
    "        self.norm_and_act = nn.Sequential(\n",
    "            nn.LayerNorm(256 * 17),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.de_conv1 = DecoderBlock(in_channels=256 + 256, out_channels=128)\n",
    "        self.de_conv2 = DecoderBlock(in_channels=128 + 128, out_channels=64)\n",
    "        self.de_conv3 = DecoderBlock(in_channels=64 + 64, out_channels=32)\n",
    "        self.de_conv4 = DecoderBlock(in_channels=32 + 32, out_channels=16)\n",
    "        self.de_conv5 = DecoderBlock(in_channels=16 + 16, out_channels=3, is_last=True)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1, 1), stride=(1, 2), padding=(0, 0))\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=257, num_heads=1, batch_first=True)\n",
    "\n",
    "    def calculate_gains(self, noisy_spec: torch.Tensor, est_spec: torch.Tensor):\n",
    "        return (est_spec.abs() / noisy_spec.abs().clamp(min=1e-6)).clamp(max=1)\n",
    "\n",
    "    def forward(self, input_spec: torch.Tensor):\n",
    "        # Feature engineering\n",
    "        x_real = input_spec.real\n",
    "        x_imag = input_spec.imag\n",
    "\n",
    "        x = torch.cat((x_real, x_imag), dim=-1)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Encoding\n",
    "        en_out1 = self.en_conv1(x)\n",
    "        en_out2 = self.en_conv2(en_out1)\n",
    "        en_out3 = self.en_conv3(en_out2)\n",
    "        en_out4 = self.en_conv4(en_out3)\n",
    "        en_out5 = self.en_conv5(en_out4)\n",
    "\n",
    "        # GRU\n",
    "        out = en_out5.permute(0, 2, 1, 3)\n",
    "        out = en_out5.contiguous().view(out.size(0), out.size(1), -1)\n",
    "        gru_out, _ = self.gru(out)\n",
    "        gru_out = self.norm_and_act(gru_out)\n",
    "        gru_out = gru_out.permute(0, 2, 1).contiguous().view(*en_out5.shape)\n",
    "\n",
    "        # Decoding\n",
    "        de_out1 = self.de_conv1(torch.cat((gru_out, en_out5), dim=1))\n",
    "        de_out2 = self.de_conv2(torch.cat((de_out1, en_out4), dim=1))\n",
    "        de_out3 = self.de_conv3(torch.cat((de_out2, en_out3), dim=1))\n",
    "        de_out4 = self.de_conv4(torch.cat((de_out3, en_out2), dim=1))\n",
    "        de_out5 = self.de_conv5(torch.cat((de_out4, en_out1), dim=1))\n",
    "\n",
    "        # Obtain masks\n",
    "        out = self.out_conv(de_out5)\n",
    "        masks = out.permute(1, 0, 2, 3)\n",
    "\n",
    "        # Complex spectrogram reconstruction\n",
    "        x_magnitude = input_spec.abs()\n",
    "        x_phase = input_spec.angle()\n",
    "        \n",
    "        mag_mask = masks[0, :].squeeze(0)\n",
    "        magnitude = torch.sigmoid(mag_mask) * x_magnitude\n",
    "\n",
    "        real_phase_mask = torch.tanh(self.attention(masks[1, :].squeeze(0), mag_mask, masks[1, :].squeeze(0))[0])\n",
    "        imag_phase_mask = torch.tanh(self.attention(masks[2, :].squeeze(0), mag_mask, masks[1, :].squeeze(0))[0])\n",
    "\n",
    "        real_phase_mask = real_phase_mask / torch.sqrt(real_phase_mask ** 2 + imag_phase_mask ** 2 + self.eps)\n",
    "        imag_phase_mask = imag_phase_mask / torch.sqrt(real_phase_mask ** 2 + imag_phase_mask ** 2 + self.eps)\n",
    "\n",
    "        real_part = magnitude * (real_phase_mask * torch.cos(x_phase) - imag_phase_mask * torch.sin(x_phase))\n",
    "        imag_part = magnitude * (real_phase_mask * torch.sin(x_phase) + imag_phase_mask * torch.cos(x_phase))\n",
    "\n",
    "        est_spec = torch.complex(real_part, imag_part)\n",
    "        gains = self.calculate_gains(input_spec, est_spec)\n",
    "        \n",
    "        return est_spec, gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.NoisySpeech(DATA_PATH, device=DEVICE)\n",
    "_, _, input_samplerate = dataset.__getitem__(0)\n",
    "\n",
    "enhancer = CRN(n_fft=N_FFT, gru_layers=GRU_LAYERS)\n",
    "enhancer.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(params=enhancer.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=100, threshold=5e-2, min_lr=5e-5)\n",
    "loss = MelLoss(sample_rate=RESAMPLE_SAMPLERATE, n_stft=N_FFT // 2 + 1, n_mels=N_MELS)\n",
    "preprocessor = PreProcessor(input_samplerate=input_samplerate, resample_samplerate=RESAMPLE_SAMPLERATE, n_fft=N_FFT, power=None)\n",
    "\n",
    "train_size = int(0.9 * len(dataset)) \n",
    "eval_size = int(0.1 * len(dataset))\n",
    "leftover = len(dataset) - train_size - eval_size\n",
    "\n",
    "train_dataset, eval_dataset, _ = torch.utils.data.random_split(dataset, [train_size, eval_size, leftover])\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data.collate_fn)\n",
    "\n",
    "train(\n",
    "    dataloader=train_dataloader,\n",
    "    dataset=train_dataset,\n",
    "    model=enhancer,\n",
    "    preprocessor=preprocessor,\n",
    "    loss_fn=loss,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f28887",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enhancer.state_dict(), SAVE_PATH + \"crn-nfft_512-nmel_50-melloss-bs_16.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f21e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = torch.load(\"./experiments/models/crn-model-512-50-b16.pt\")\n",
    "\n",
    "# eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=True, collate_fn=data.collate_fn)\n",
    "# noisy_batch, clean_batch, sr = next(iter(eval_loader))\n",
    "# noisy_spec = preprocessor(noisy_batch).to(device)\n",
    "# clean_spec = preprocessor(clean_batch).to(device)\n",
    "\n",
    "# postprocessor = PostProcessor(output_samplerate=input_samplerate, n_fft=n_fft)\n",
    "\n",
    "# loaded_model.eval()\n",
    "# with torch.no_grad():\n",
    "#     enhanced_spec, _ = loaded_model(noisy_spec)\n",
    "\n",
    "# enhanced_batch = postprocessor(enhanced_spec.to('cpu'))\n",
    "# clean_audio = postprocessor(clean_spec.to('cpu'))\n",
    "# noisy_audio = postprocessor(noisy_spec.to('cpu'))\n",
    "\n",
    "# idx = np.random.randint(16)\n",
    "# plt.figure(figsize=(8,3))\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(noisy_spec[idx,:,:].to('cpu').abs().log().mT.numpy(),origin='lower', aspect=\"auto\")\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(enhanced_spec[idx,:,:].to('cpu').abs().log().mT.detach().numpy(),origin='lower', aspect=\"auto\")\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(clean_spec[idx,:,:].to('cpu').abs().log().mT.numpy(),origin='lower', aspect=\"auto\")\n",
    "# plt.show()\n",
    "\n",
    "# import IPython\n",
    "# IPython.display.display(IPython.display.Audio(noisy_batch[idx,:].detach().numpy(),rate=int(sr)))\n",
    "# IPython.display.display(IPython.display.Audio(enhanced_batch[idx,:].detach().numpy(),rate=int(sr)))\n",
    "# IPython.display.display(IPython.display.Audio(clean_batch[idx,:],rate=int(sr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
